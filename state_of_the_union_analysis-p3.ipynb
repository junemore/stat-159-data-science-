{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An analysis of the State of the Union speeches - Part 3\n",
    "# Word analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "import shelve\n",
    "\n",
    "plt.style.use('seaborn-dark')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data we need from previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>n_sent</th>\n",
       "      <th>n_words_all</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_uwords</th>\n",
       "      <th>n_swords</th>\n",
       "      <th>n_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>State of the Union Address</td>\n",
       "      <td>1790-01-08</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>6753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>State of the Union Address</td>\n",
       "      <td>1790-12-08</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>8455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>State of the Union Address</td>\n",
       "      <td>1791-10-25</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>14203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>State of the Union Address</td>\n",
       "      <td>1792-11-06</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>12764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>George Washington</td>\n",
       "      <td>State of the Union Address</td>\n",
       "      <td>1793-12-03</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>11696.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             president                        title       date  n_sent  \\\n",
       "0    George Washington   State of the Union Address 1790-01-08    24.0   \n",
       "1    George Washington   State of the Union Address 1790-12-08    40.0   \n",
       "2    George Washington   State of the Union Address 1791-10-25    60.0   \n",
       "3    George Washington   State of the Union Address 1792-11-06    61.0   \n",
       "4    George Washington   State of the Union Address 1793-12-03    56.0   \n",
       "\n",
       "   n_words_all  n_words  n_uwords  n_swords  n_chars  \n",
       "0       1178.0    538.0     398.0     356.0   6753.0  \n",
       "1       1515.0    683.0     516.0     463.0   8455.0  \n",
       "2       2487.0   1136.0     740.0     626.0  14203.0  \n",
       "3       2298.0   1042.0     693.0     580.0  12764.0  \n",
       "4       2132.0    972.0     720.0     652.0  11696.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = pd.read_hdf('results/df2.h5', 'addresses')\n",
    "addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with shelve.open('results/vars2') as db:\n",
    "    speech_words = db['speech_words']\n",
    "    speeches_cleaned = db['speeches_cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a single set of all unique words across all speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19219"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_list_words=[]\n",
    "for i in speeches_cleaned:\n",
    "    single_list_words.extend(i)\n",
    "unique_words=set(single_list_words)\n",
    "n_words=len(unique_words)\n",
    "n_words \n",
    "# number of unique words across all speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a word matrix, whose columns are word vectors for each speech. A word vector contains the word counts for each word across the entire document set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_vector(doc, vocab):\n",
    "    \"\"\"Return a word vector for the input document in the context of a given vocabulary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    doc: iterable of words\n",
    "       \n",
    "    vocab : iterable of words\n",
    "    integer, size of the entire vocabulary across documents.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    array\n",
    "        An integer array, of length equal to `len(vocab)`, containing the count for each\n",
    "        word in `doc` at its corresponding position in `vocab`.\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    \n",
    "    >>> doc = \"b c b c e\".split()\n",
    "    ... vocab = \"a b c d e f\".split()\n",
    "    ... word_vector(doc, vocab)\n",
    "    ... \n",
    "    array([0, 2, 2, 0, 1, 0])\n",
    "    \"\"\"\n",
    "    counts=[]\n",
    "    count=0\n",
    "    for i in np.arange(len(vocab)):\n",
    "        for letter in doc:\n",
    "            if vocab[i]==letter:\n",
    "                count+=1\n",
    "        counts.append(count)\n",
    "        count=0\n",
    "       \n",
    "    return counts\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a simple unit test for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_word_vector():\n",
    "    doc = \"b c b c e\".split()\n",
    "    vocab = \"a b c d e f\".split()\n",
    "    wv = word_vector(doc, vocab)\n",
    "    np.testing.assert_equal(wv, np.array([0, 2, 2, 0, 1, 0]) )\n",
    "\n",
    "test_word_vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make the word matrix for our entire set of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_vecotr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-81d2a14ede44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_vecotr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_set_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m510\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_vecotr' is not defined"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "word_vector(single_set_words,)\n",
    "wmat[500:510]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How sparse is this matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmat is comprised of 93.19% zeros.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print(f\"wmat is comprised of {100*sparsity:.2f}% zeros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate results storage\n",
    "\n",
    "We'll need a few results for the next step, so let's store them in a new set of HDF5/shelve stores for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wmat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-daf7cfb86494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/df3.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wmat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mshelve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/vars3'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unique_words'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wmat' is not defined"
     ]
    }
   ],
   "source": [
    "wmat.to_hdf('results/df3.h5', 'wmat')\n",
    "with shelve.open('results/vars3') as db:\n",
    "    db['unique_words'] = unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
